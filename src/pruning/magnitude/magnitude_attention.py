import torch
import numpy as np
from tqdm import tqdm
import sys
import os

# ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë³€ê²½
os.chdir('/content/drive/MyDrive/smartfarm_pruning')

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append('.')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = "/content/drive/MyDrive/smartfarm_pruning"
if project_root not in sys.path:
    sys.path.append(project_root)

# utils í•¨ìˆ˜ë“¤ import (ì§€ì¹¨ì— ë”°ë¼)
from src.utils.model_loader import load_model
from src.utils.data_loader import save_json

# í”„ë£¨ë‹ ì„¤ì •
PRUNE_RATIO = 0.05  # 5% í”„ë£¨ë‹
MODEL_PATH = "models/original/gemma-3-1b-pt"
OUTPUT_FILE = "results/magnitude_heads_to_prune.json"


def calculate_head_importance(model):
    """
    ëª¨ë“  ë ˆì´ì–´ì˜ attention heads ì¤‘ìš”ë„ ê³„ì‚°
    
    Args:
        model: ë¡œë“œëœ ëª¨ë¸
        
    Returns:
        head_scores: Dict[layer_idx][head_idx] = score
    """
    
    print("ğŸ” Attention heads ì¤‘ìš”ë„ ê³„ì‚° ì¤‘...")
    
    config = model.config
    num_layers = config.num_hidden_layers
    num_q_heads = config.num_attention_heads
    num_kv_heads = getattr(config, 'num_key_value_heads', num_q_heads)
    head_dim = config.hidden_size // num_q_heads
    
    print(f"  ë¶„ì„ ëŒ€ìƒ: {num_layers}ê°œ ë ˆì´ì–´ Ã— {num_q_heads}ê°œ í—¤ë“œ = {num_layers * num_q_heads}ê°œ")
    
    head_scores = {}
    model.eval()
    
    with torch.no_grad():
        for layer_idx in tqdm(range(num_layers), desc="ë ˆì´ì–´ ìˆœíšŒ"):
            
            try:
                # ê° í—¤ë“œì˜ Q, K, V ê°€ì¤‘ì¹˜ ì¶”ì¶œ
                attention = model.model.layers[layer_idx].self_attn
                
                q_weight = attention.q_proj.weight.data
                k_weight = attention.k_proj.weight.data
                v_weight = attention.v_proj.weight.data
                
                # GQA êµ¬ì¡° ì²˜ë¦¬: K,Vë¥¼ Q í—¤ë“œ ìˆ˜ì— ë§ê²Œ í™•ì¥
                if num_kv_heads < num_q_heads:
                    repeat_factor = num_q_heads // num_kv_heads
                    k_expanded = []
                    v_expanded = []
                    
                    for kv_head_idx in range(num_kv_heads):
                        k_start = kv_head_idx * head_dim
                        k_end = (kv_head_idx + 1) * head_dim
                        v_start = kv_head_idx * head_dim
                        v_end = (kv_head_idx + 1) * head_dim
                        
                        k_head = k_weight[k_start:k_end, :]
                        v_head = v_weight[v_start:v_end, :]
                        
                        for _ in range(repeat_factor):
                            k_expanded.append(k_head)
                            v_expanded.append(v_head)
                    
                    k_weight_expanded = torch.cat(k_expanded, dim=0)
                    v_weight_expanded = torch.cat(v_expanded, dim=0)
                else:
                    k_weight_expanded = k_weight
                    v_weight_expanded = v_weight
                
            except Exception as e:
                print(f"âš ï¸ ë ˆì´ì–´ {layer_idx} ìŠ¤í‚µ: {e}")
                continue
            
            # ê° í—¤ë“œë³„ ì ˆëŒ“ê°’ í‰ê·  ê³„ì‚°
            layer_head_scores = {}
            
            for head_idx in range(num_q_heads):
                try:
                    start = head_idx * head_dim
                    end = (head_idx + 1) * head_dim
                    
                    q_head = q_weight[start:end, :]
                    k_head = k_weight_expanded[start:end, :]
                    v_head = v_weight_expanded[start:end, :]
                    
                    # ì ˆëŒ“ê°’ í‰ê·  ê³„ì‚°
                    q_magnitude = torch.mean(torch.abs(q_head)).item()
                    k_magnitude = torch.mean(torch.abs(k_head)).item()
                    v_magnitude = torch.mean(torch.abs(v_head)).item()
                    
                    # ìœ íš¨ì„± ê²€ì¦
                    if (np.isnan(q_magnitude) or np.isnan(k_magnitude) or np.isnan(v_magnitude) or
                        np.isinf(q_magnitude) or np.isinf(k_magnitude) or np.isinf(v_magnitude)):
                        layer_head_scores[head_idx] = 0.0
                        continue
                    
                    # Q, K, V í‰ê· ìœ¼ë¡œ ì „ì²´ ì¤‘ìš”ë„
                    importance = (q_magnitude + k_magnitude + v_magnitude) / 3.0
                    layer_head_scores[head_idx] = importance
                    
                except Exception as e:
                    layer_head_scores[head_idx] = 0.0
            
            head_scores[layer_idx] = layer_head_scores
    
    total_heads = sum(len(scores) for scores in head_scores.values())
    valid_heads = sum(len([s for s in scores.values() if s > 0]) for scores in head_scores.values())
    
    print(f" ë¶„ì„ ì™„ë£Œ: {total_heads}ê°œ í—¤ë“œ ì¤‘ {valid_heads}ê°œ ìœ íš¨")
    
    return head_scores


def select_heads_to_prune(head_scores, ratio=0.05):
    """
    ì¤‘ìš”ë„ ë‚®ì€ N% ì„ íƒ
    
    Args:
        head_scores: calculate_head_importance()ì˜ ì¶œë ¥
        ratio: í”„ë£¨ë‹í•  ë¹„ìœ¨ (ê¸°ë³¸ê°’: 30%)
        
    Returns:
        heads_to_prune: List[(layer, head)] í”„ë£¨ë‹í•  í—¤ë“œë“¤
    """
    
    print(f" ì¤‘ìš”ë„ ì •ë ¬ ë° í•˜ìœ„ {ratio:.1%} ì„ íƒ")
    
    if not head_scores:
        print("âŒ ìœ íš¨í•œ í—¤ë“œ ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return []
    
    # ëª¨ë“  í—¤ë“œë¥¼ (ì¤‘ìš”ë„, ë ˆì´ì–´, í—¤ë“œ) í˜•íƒœë¡œ ìˆ˜ì§‘
    all_heads = []
    zero_heads = []
    
    for layer_idx, layer_heads in head_scores.items():
        for head_idx, importance in layer_heads.items():
            if importance > 0:
                all_heads.append((importance, layer_idx, head_idx))
            else:
                zero_heads.append((0.0, layer_idx, head_idx))
    
    print(f"  ìœ íš¨í•œ í—¤ë“œ: {len(all_heads)}ê°œ")
    print(f"  ë¬´íš¨í•œ í—¤ë“œ: {len(zero_heads)}ê°œ")
    
    if len(all_heads) == 0:
        print("âŒ í”„ë£¨ë‹í•  ìœ íš¨í•œ í—¤ë“œê°€ ì—†ìŠµë‹ˆë‹¤!")
        return []
    
    # ì¤‘ìš”ë„ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ë‚®ì€ ì¤‘ìš”ë„ê°€ ì•ì—)
    all_heads.sort(key=lambda x: x[0])
    
    # ë¬´íš¨í•œ í—¤ë“œë¥¼ ë¨¼ì € í”„ë£¨ë‹í•˜ê³ , ê·¸ ë‹¤ìŒì— ë‚®ì€ ì¤‘ìš”ë„ í—¤ë“œ
    combined_heads = zero_heads + all_heads
    
    total_heads = len(combined_heads)
    num_to_prune = int(total_heads * ratio)
    
    print(f"  ì „ì²´ í—¤ë“œ: {total_heads}ê°œ")
    print(f"  í”„ë£¨ë‹ ì˜ˆì •: {num_to_prune}ê°œ")
    
    # í•˜ìœ„ N% ì„ íƒ
    heads_to_prune = []
    for i in range(min(num_to_prune, len(combined_heads))):
        importance, layer_idx, head_idx = combined_heads[i]
        heads_to_prune.append((layer_idx, head_idx))
    
    # í†µê³„ ì¶œë ¥
    pruned_by_layer = {}
    for layer_idx, head_idx in heads_to_prune:
        pruned_by_layer[layer_idx] = pruned_by_layer.get(layer_idx, 0) + 1
    
    print(f"\n ë ˆì´ì–´ë³„ í”„ë£¨ë‹ ë¶„í¬:")
    for layer_idx in sorted(head_scores.keys()):
        pruned = pruned_by_layer.get(layer_idx, 0)
        total_in_layer = len(head_scores[layer_idx])
        percentage = pruned / total_in_layer * 100
        print(f"  ë ˆì´ì–´ {layer_idx:2d}: {pruned:2d}/{total_in_layer} ({percentage:5.1f}%)")
    
    return heads_to_prune


# í…ŒìŠ¤íŠ¸ ì½”ë“œ 
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ” Attention Heads Magnitude ì¤‘ìš”ë„ ë¶„ì„")
    print("=" * 60)
    
    try:
        # 1. ëª¨ë¸ ë¡œë“œ (utils í•¨ìˆ˜ ì‚¬ìš©)
        print(f" ëª¨ë¸ ë¡œë“œ: {MODEL_PATH}")
        model, tokenizer = load_model(MODEL_PATH)
        
        # 2. ì¤‘ìš”ë„ ê³„ì‚°
        scores = calculate_head_importance(model)
        
        if not scores:
            print("âŒ ì¤‘ìš”ë„ ê³„ì‚° ì‹¤íŒ¨!")
            exit(1)
        
        # 3. í”„ë£¨ë‹ ëŒ€ìƒ ì„ íƒ
        targets = select_heads_to_prune(scores, PRUNE_RATIO)
        
        if not targets:
            print("âŒ í”„ë£¨ë‹ ëŒ€ìƒ ì„ íƒ ì‹¤íŒ¨!")
            exit(1)
        
        # 4. ê²°ê³¼ ì €ì¥ 
        print(f"\n ê²°ê³¼ ì €ì¥: {OUTPUT_FILE}")
        
        # [{"layer": x, "head": y}, ...]
        result_data = []
        for layer_idx, head_idx in targets:
            result_data.append({
                "layer": layer_idx,
                "head": head_idx
            })
        
        save_json(result_data, OUTPUT_FILE)
        
        print("\n" + "=" * 60)
        print(" Attention heads ë¶„ì„ ì™„ë£Œ!")
        print(f" í”„ë£¨ë‹ ë¹„ìœ¨: {PRUNE_RATIO:.1%}")
        print(f" í”„ë£¨ë‹ í—¤ë“œ ìˆ˜: {len(targets)}ê°œ")
        print(f" ê²°ê³¼ íŒŒì¼: {OUTPUT_FILE}")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()