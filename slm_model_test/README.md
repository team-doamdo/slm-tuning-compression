## 실행 환경

### 하드웨어 구성
- **개발 환경**: Apple Silicon (M1/M2) 탑재 MacBook
- **가속 기술**: Metal Performance Shaders (MPS) 활용
- **타겟 디바이스**: 라즈베리 파이 (최종 배포용)

### GPU 가속 설정
- **MPS (Metal Performance Shaders)** 백엔드 사용으로 Apple Silicon GPU 활용
- PyTorch의 MPS 지원을 통한 학습 및 추론 가속
- 환경 변수 설정: `PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0` (메모리 제한 해제)

### 프레임워크 호환성
- PyTorch 2.0+ (MPS 지원 버전)
- float32 정밀도 사용 (MPS 안정성 고려)
- eager attention 구현 사용 (MPS 호환성)

## 프로젝트 구조

### 핵심 파일

#### main.py (구현 코드)
프로젝트의 전체 파이프라인을 구현한 메인 실행 파일. 모델 로딩부터 프루닝, 파인튜닝, 성능 평가까지 모든 과정이 통합되어 있음.

주요 구성 요소:
- **ModelPruner**: 구조적 프루닝 수행 클래스
- **LoRAFineTuner**: LoRA 파인튜닝 관리 클래스  
- **PerformanceEvaluator**: 성능 측정 및 리포트 생성 클래스
- **TomatoQADataset**: 토마토 Q&A 데이터셋 처리 클래스

#### tomato_qa_dataset.json (학습 데이터)
토마토 재배 전문 지식을 담은 415개의 고품질 Q&A 데이터셋.

**카테고리별 분포:**
- **질병 관리 (disease_management)**: 40% (166개)
  - 병해충 진단, 예방 및 치료 방법
  - 유기농 재배 시 질병 관리 전략
  - 저항성 품종 활용법
  
- **환경 제어 (environmental_control)**: 30% (125개)
  - 온도, 습도, CO2, 광량 최적화
  - 에너지 효율적 환경 관리
  - 계절별 환경 조절 전략
  
- **영양 및 생육 (nutrition_growth)**: 20% (83개)
  - 생육 단계별 영양 관리
  - pH, EC 조절 방법
  - 수경재배 영양 솔루션
  
- **장비 및 센서 (equipment_sensors)**: 5% (20개)
  - 센서 캘리브레이션 및 유지보수
  - 관수 시스템 최적화
  
- **문제 해결 (troubleshooting)**: 5% (21개)
  - 일반적인 재배 문제 진단
  - 경제성 분석 및 인증 관련

각 데이터는 실제 농업 현장의 시나리오를 반영하여 구성됨. 긴급 상황 대응부터 장기적 재배 전략까지 포괄함.

#### validation_questions.json (검증 데이터)
모델 성능 평가용 15개 핵심 질문 세트. 실제 농가에서 자주 발생하는 문제 상황을 중심으로 구성됨.

#### performance_report.json (성능 리포트)
경량화 후 모델의 성능 측정 결과를 담은 JSON 파일.

#### log.txt (실행 로그)
전체 프로세스의 실행 로그로, 각 단계별 진행 상황과 결과가 기록되어 있음.

## 적용된 경량화 기법

### 1. 구조적 프루닝 (Structured Pruning)

#### 적응형 FFN 프루닝
Feed-Forward Network의 중간 차원을 선택적으로 축소하는 기법을 적용함.

**구현 특징:**
- **레이어 중요도 평가**: 가중치 크기 분석과 토마토 관련 텍스트 반응성을 기반으로 각 레이어의 중요도를 계산
- **보호 메커니즘**: 입출력 레이어(0-3, 22-25층)는 중요도가 높아 프루닝에서 제외
- **단계적 프루닝**: 90% → 85% → 80% → 75% 순서로 점진적으로 뉴런을 줄이며 각 단계마다 검증
- **검증 기준**: 5개 테스트 프롬프트로 텍스트 생성 능력 확인 (영어 텍스트, 특수 토큰 없음, 반복성 체크)

**프루닝 결과:**
- 원본 intermediate size: 6912 뉴런
- 최종 intermediate size: 5184 뉴런 (75% 유지)
- 18개 레이어 프루닝, 8개 레이어 보호
- 모델 크기: 3814MB → 3404MB (10.8% 감소)

### 2. LoRA 파인튜닝 (Low-Rank Adaptation)

프루닝으로 손실된 성능을 회복하고 토마토 재배 전문성을 추가하기 위해 LoRA를 적용함.

**초기 설정 (코드 상단):**
- **Rank (r)**: 16 - 표현력 향상을 위해 증가
- **Alpha**: 32 - 학습 강도 조절
- **Target modules**: q_proj, v_proj, k_proj, o_proj - 4개 어텐션 모듈

**실제 적용 (메모리 제약으로 수정):**
- **Rank (r)**: 4 - 메모리 절약을 위해 축소
- **Alpha**: 32 - 유지
- **Target modules**: q_proj, v_proj - 2개 모듈로 축소
- **학습 가능 파라미터**: 372,736개 (전체의 0.04%)

**학습 과정:**
- 3 epochs 진행
- 배치 크기: 1 (메모리 제약)
- 학습률: 2e-5
- Gradient clipping 적용 (max_norm=0.5)
- 각 에포크별 손실: 13.89 → 6.47 → 6.11

**학습 환경 특이사항:**
- Apple Silicon MPS 사용으로 CUDA 대비 다른 메모리 관리
- float16 대신 float32 사용 (MPS 안정성)
- MPS 메모리 캐시 정리: `torch.mps.empty_cache()` 주기적 실행

## 성능 분석

### 달성된 성과

#### 기술적 목표 달성
- **모델 크기**: 3405.62 MB (목표 6000MB 이내 달성) 
- **평균 응답 시간**: 5.71초 (목표 10초 이내 달성) 
- **최대 응답 시간**: 8.18초 
- **메모리 사용량**: 평균 1264MB, 최대 1345MB 

#### 크기 감소 효과
- 원본 모델: 3814.26 MB
- 프루닝 후: 3404.20 MB
- 최종 모델: 3405.62 MB
- **총 크기 감소율**: 10.7%

### 문제점 및 한계

#### 1. 텍스트 생성 품질 저하
검증 결과 생성된 텍스트가 심각하게 손상됨:
- 무의미한 숫자 반복 
- 문법 파괴 및 비논리적 문장 구조
- 토마토 재배 관련 전문 답변 생성 실패

#### 2. 프루닝의 부작용
- 75% 뉴런 유지에도 불구하고 언어 모델 기능이 크게 손상됨
- 레이어 중요도 평가가 실제 언어 생성 능력과 불일치
- 보호 레이어(8개)가 충분하지 않았을 가능성

#### 3. LoRA 파인튜닝 한계
- 매우 낮은 rank(4) 사용으로 표현력 부족
- 메모리 제약으로 target modules를 2개로 축소 (원래 4개 계획)
- 손상된 베이스 모델에 대한 파인튜닝으로 개선 효과 미미
- 학습 중 높은 초기 손실값(13.89)이 모델 손상을 시사

#### 4. 검증 프로세스의 문제
- 프루닝 단계의 검증이 실제 품질을 제대로 평가하지 못함
- 80% 검증 통과 기준이 너무 관대했을 가능성
